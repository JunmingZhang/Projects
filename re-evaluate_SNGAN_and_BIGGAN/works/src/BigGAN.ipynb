{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BigGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVRH7zSa2Zoj"
      },
      "source": [
        "pip install fid-score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW5drKMaJn7Z"
      },
      "source": [
        "!git clone https://github.com/JunmingZhang/BigGAN-image-generation.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdA4HKbfKapJ"
      },
      "source": [
        "cd BigGAN-image-generation/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFPejR4aKgon"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1nAle7FCVFZdix2--ks0r5JBkFnKw8ctW"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP5nbDOop5vA"
      },
      "source": [
        "!unzip BigGAN_ch96_bs256x8_138k.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dxobsHm5df6"
      },
      "source": [
        "mv 138k/G_ema.pth data/G_ema.pth"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sdw84oTRzydN"
      },
      "source": [
        "<h1> Train </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFnT9bcv0sfP"
      },
      "source": [
        "# !python train.py --dataset flowers --gpu 0 --pretrained ./data/G_ema.pth --iters 500\n",
        "# !python train.py --dataset anime --gpu 0 --pretrained ./data/G_ema.pth --resume \"/content/checkpoint_anime_iter7500.pth.tar\" --iters 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9Dek_FYz0MT"
      },
      "source": [
        "<h1> Test </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOTSDxih-3Kd"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import matplotlib\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "import shutil\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from models.setup_model import setup_model\n",
        "from dataloaders.setup_dataloader_smallgan import setup_dataloader\n",
        "\n",
        "from fid_score import fid_score\n",
        "\n",
        "def reconstruct(model,out_path,indices):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    dataset_size = model.embeddings.weight.size()[0]\n",
        "    assert type(indices)==torch.Tensor\n",
        "    indices = indices.to(device)        \n",
        "    embeddings = model.embeddings(indices)\n",
        "    batch_size = embeddings.size()[0]\n",
        "    image_tensors = model(embeddings)\n",
        "    with torch.no_grad():\n",
        "        torchvision.utils.save_image(\n",
        "            image_tensors,\n",
        "            out_path,\n",
        "            nrow=int(batch_size ** 0.5),\n",
        "            normalize=True,\n",
        "        )\n",
        "        \n",
        "        \n",
        "#see https://github.com/nogu-atsu/SmallGAN/blob/2293700dce1e2cd97e25148543532814659516bd/gen_models/ada_generator.py#L37-L53\n",
        "def interpolate(model, iteration, input_path, out_path, source, dist, trncate=0.4, num=5):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    dataset_size = model.embeddings.weight.size()[0]\n",
        "    indices = torch.tensor([source,dist],device=device)\n",
        "    indices = indices.to(device) \n",
        "    embeddings = model.embeddings(indices)\n",
        "    embeddings = embeddings[[0]] * torch.linspace(1, 0, num,device=device)[:, None] + embeddings[[1]]* torch.linspace(0, 1, num,device=device)[:, None]\n",
        "    batch_size = embeddings.size()[0]\n",
        "    image_tensors = model(embeddings)\n",
        "    print(image_tensors.shape)\n",
        "    print(batch_size)\n",
        "    if not os.path.exists(out_path + str(iteration)):\n",
        "        os.makedirs(out_path + str(iteration) + \"/\")\n",
        "    out_path = out_path + str(iteration) + \"/\"\n",
        "    inputs = os.listdir(input_path)\n",
        "    with torch.no_grad():\n",
        "        for i in range(len(image_tensors)):\n",
        "            torchvision.utils.save_image(\n",
        "                image_tensors[i],\n",
        "                out_path + inputs[i],\n",
        "                nrow=batch_size,\n",
        "                normalize=True,\n",
        "            )\n",
        "\n",
        "#from https://github.com/nogu-atsu/SmallGAN/blob/2293700dce1e2cd97e25148543532814659516bd/gen_models/ada_generator.py#L37-L53        \n",
        "def random(model, iteration, input_path, out_path, tmp=0.4, n=9, truncate=False):\n",
        "    from scipy.stats import truncnorm\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    dataset_size = model.embeddings.weight.size()[0]\n",
        "    dim_z = model.embeddings.weight.size(1)\n",
        "    if truncate:\n",
        "        embeddings = truncnorm(-tmp, tmp).rvs(n * dim_z).astype(\"float32\").reshape(n, dim_z)\n",
        "    else:\n",
        "        embeddings = np.random.normal(0, tmp, size=(n, dim_z)).astype(\"float32\")\n",
        "    embeddings = torch.tensor(embeddings,device=device)\n",
        "    batch_size = embeddings.size()[0]\n",
        "    image_tensors = model(embeddings)\n",
        "    print(image_tensors.shape)\n",
        "    print(batch_size)\n",
        "    print(device)\n",
        "    if not os.path.exists(out_path + str(iteration)):\n",
        "        os.makedirs(out_path + str(iteration) + \"/\")\n",
        "    out_path = out_path + str(iteration) + \"/\"\n",
        "    inputs = os.listdir(input_path)\n",
        "    with torch.no_grad():\n",
        "        for i in range(len(image_tensors)):\n",
        "            torchvision.utils.save_image(\n",
        "                image_tensors[i],\n",
        "                out_path + inputs[i],\n",
        "                nrow=int(batch_size ** 0.5),\n",
        "                normalize=True,\n",
        "            )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trzSkxOO7rHW"
      },
      "source": [
        "# Although we have interpolate and random here, we only focus on the reconstruction in the research\n",
        "if os.path.exists('biggan_generations'):\n",
        "    shutil.rmtree('/content/BigGAN-image-generation/biggan_generations')\n",
        "if not os.path.exists('biggan_generations'):\n",
        "    os.makedirs('biggan_generations')\n",
        "\n",
        "    os.makedirs('biggan_generations/reconstruct')\n",
        "    os.makedirs('biggan_generations/reconstruct/anime')\n",
        "    os.makedirs('biggan_generations/reconstruct/face')\n",
        "    os.makedirs('biggan_generations/reconstruct/flowers')\n",
        "\n",
        "    os.makedirs('biggan_generations/interpolate')\n",
        "    os.makedirs('biggan_generations/interpolate/anime')\n",
        "    os.makedirs('biggan_generations/interpolate/face')\n",
        "    os.makedirs('biggan_generations/interpolate/flowers')\n",
        "\n",
        "    os.makedirs('biggan_generations/random')\n",
        "    os.makedirs('biggan_generations/random/anime')\n",
        "    os.makedirs('biggan_generations/random/face')\n",
        "    os.makedirs('biggan_generations/random/flowers')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiF96ABIAeEh"
      },
      "source": [
        "# Specify the target dataset and iteration here\n",
        "dataset = \"flowers\"\n",
        "iteration = 5000\n",
        "l = len(os.listdir(\"data/\" + dataset))\n",
        "print(l)\n",
        "dataloader = setup_dataloader(dataset, batch_size=2)\n",
        "\n",
        "# Uncomment the following two lines if you are using the trained models obtained by previous training commands.\n",
        "# exp_dir = \"./experiments/train_dataset-flowers_model-biggan128-ada_2021-04-13-17-17-00/\"\n",
        "# model = setup_model(\"biggan128-ada\", dataset_size=l, resume=exp_dir+\"checkpoint_\" + dataset + \"_iter\" + str(iteration) + \".pth.tar\")\n",
        "\n",
        "# Uncomment the following two lines if you are using the trained models already in ./pretrained/\n",
        "# We put the trained models in this folder while testing, sometimes they were trained few hours ago from the testing time.\n",
        "# You should create the new folder \"pretrained\" by yourself, this folder does not exist by default\n",
        "# exp_dir = \"./pretrained/\"\n",
        "# model = setup_model(\"biggan128-ada\", dataset_size=l, resume=exp_dir + \"checkpoint_\" + dataset + \"_iter\" + str(iteration) + \".pth.tar\")\n",
        "\n",
        "model = model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs-4AHmcAvFt"
      },
      "source": [
        "reconstruct(model, iteration, input_path=\"./data/\" + dataset + \"/\", out_path=\"./biggan_generations/reconstruct/\" + dataset + \"/\", indices=torch.arange(l))\n",
        "interpolate(model, iteration, input_path=\"./data/\" + dataset + \"/\", out_path=\"./biggan_generations/interpolate/\" + dataset + \"/\", source=1, dist=2)\n",
        "random(model, iteration, input_path=\"./data/\" + dataset + \"/\", out_path=\"./biggan_generations/random/\" + dataset + \"/\", tmp=0.2, n=l, truncate=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}